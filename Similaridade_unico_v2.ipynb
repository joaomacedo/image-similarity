{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import csv\n",
    "import sys\n",
    "import requests\n",
    "import skimage.io\n",
    "import os\n",
    "import os.path\n",
    "\n",
    "import glob\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "from keras.applications import VGG16\n",
    "import datetime\n",
    "\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.preprocessing import image as kimage\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "\n",
    "import skimage.io\n",
    "import hashlib\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "import math\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "from shutil import copyfile\n",
    "\n",
    "from PIL import Image as pimage, ExifTags\n",
    "from PIL.ExifTags import TAGS\n",
    "\n",
    "from similaridade import *\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"inicio\")\n",
    "print(datetime.datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d %H:%M:%S'))\n",
    "\n",
    "gera_arqs = True\n",
    "gera_dados = True\n",
    "sim_tensorflow = True\n",
    "\n",
    "arqs = {}\n",
    "arqs[\"busca\"] = {}\n",
    "arqs[\"material\"] = {}\n",
    "arqs[\"extensoes_img\"] = ['.jpg', '.png', '.tif', '.jpeg', '.gif', '.bmp']\n",
    "\n",
    "arqs[\"busca\"][\"raiz\"] = \"./img_busca/\"\n",
    "arqs[\"busca\"][\"nome_exibicao\"] = \"CD Anexo\"\n",
    "arqs[\"busca\"][\"nomes\"] = []\n",
    "arqs[\"busca\"][\"hashs\"] = {}\n",
    "\n",
    "arqs[\"material\"][\"raiz\"] = \"./img_quest/\"\n",
    "arqs[\"material\"][\"nome_exibicao\"] = \"HD Examinado\"\n",
    "arqs[\"material\"][\"nomes\"] = []\n",
    "arqs[\"material\"][\"hashs\"] = {}\n",
    "\n",
    "if gera_arqs:\n",
    "    print(\"\\ngera arqs\")\n",
    "    print(datetime.datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d %H:%M:%S'))\n",
    "    get_arquivos_hashs(\"busca\", arqs)\n",
    "    get_arquivos_hashs(\"material\", arqs)\n",
    "    grava_arqs(arqs)\n",
    "else:\n",
    "    print(\"\\nle arqs\")\n",
    "    print(datetime.datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d %H:%M:%S'))\n",
    "    arqs = le_arqs()\n",
    "\n",
    "print(\"busca keys = \", len(arqs[\"busca\"][\"hashs\"].keys() ) )\n",
    "print(\"busca nomes = \",len(arqs[\"busca\"][\"nomes\"]))\n",
    "print(\"material keys = \", len(arqs[\"material\"][\"hashs\"].keys() ) )\n",
    "print(\"material nomes = \",len(arqs[\"material\"][\"nomes\"]))\n",
    "\n",
    "#print(\"\\nestrutura arqs\")\n",
    "#print_arqs(arqs)\n",
    "\n",
    "print(\"\\n\\ntestes...\")\n",
    "print(datetime.datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d %H:%M:%S'))\n",
    "\n",
    "rand_img = os.path.join(arqs[\"busca\"][\"raiz\"] ,np.random.choice(arqs[\"busca\"][\"nomes\"]))\n",
    "print(rand_img)\n",
    "print(os.path.isfile(rand_img))\n",
    "\n",
    "try:\n",
    "    img = skimage.io.imread(rand_img)\n",
    "    print(img.shape)\n",
    "except:\n",
    "    print(\"erro de leitura do arquivo\", rand_img)  \n",
    "    \n",
    "img = kimage.load_img(rand_img, target_size=(224, 224))\n",
    "x = kimage.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "print(x.shape)\n",
    "\n",
    "print(\"\\ncarrega vgg16\")\n",
    "print(datetime.datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d %H:%M:%S'))\n",
    "# image_top=False removes final connected layers\n",
    "model = VGG16(include_top=False, weights='vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5')\n",
    "\n",
    "pred = model.predict(x)\n",
    "print(pred.shape)\n",
    "print(pred.ravel().shape)\n",
    "\n",
    "pred = model.predict(x)\n",
    "\n",
    "print(\"\\nmonta dados\")\n",
    "print(datetime.datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d %H:%M:%S'))\n",
    "\n",
    "dados = {}\n",
    "dados[\"busca\"]    = {}\n",
    "dados[\"material\"] = {}\n",
    "dados[\"total\"]    = {}\n",
    "\n",
    "dados[\"busca\"][\"itens\"] = []\n",
    "dados[\"busca\"][\"nomes\"] = []\n",
    "\n",
    "dados[\"material\"][\"itens\"] = []\n",
    "dados[\"material\"][\"nomes\"] = []\n",
    "\n",
    "dados[\"total\"][\"itens\"] = []\n",
    "dados[\"total\"][\"nomes\"] = []\n",
    "\n",
    "dados[\"predicoes\"]    = None\n",
    "dados[\"predicoescsr\"] = None\n",
    "dados[\"sim\"]          = None\n",
    "\n",
    "dados[\"busca\"][\"itens\"]=list(arqs[\"busca\"][\"hashs\"].items())\n",
    "dados[\"busca\"][\"nomes\"] = [os.path.join(arqs[\"busca\"][\"raiz\"] ,f[1][0]) for f in dados[\"busca\"][\"itens\"]]\n",
    "\n",
    "dados[\"material\"][\"itens\"]=list(arqs[\"material\"][\"hashs\"].items())\n",
    "dados[\"material\"][\"nomes\"] = [os.path.join(arqs[\"material\"][\"raiz\"] ,f[1][0]) for f in dados[\"material\"][\"itens\"]]\n",
    "\n",
    "dados[\"total\"][\"itens\"] = dados[\"busca\"][\"itens\"] + dados[\"material\"][\"itens\"]\n",
    "dados[\"total\"][\"nomes\"] = dados[\"busca\"][\"nomes\"] + dados[\"material\"][\"nomes\"]\n",
    "\n",
    "#print(\"\\nestrutura dados\")\n",
    "# estrutura de dados\n",
    "#print_dados(dados)\n",
    "\n",
    "print(\"\\ncheca dados\")\n",
    "    \n",
    "#sanity check - se imprimir alguma coisa tem algo errado\n",
    "for i in range(0, len(dados[\"busca\"][\"itens\"])):\n",
    "    x1 = dados[\"busca\"][\"itens\"][i]\n",
    "    x2 = dados[\"busca\"][\"nomes\"][i]\n",
    "    y1 = dados[\"total\"][\"itens\"][i]\n",
    "    y2 = dados[\"total\"][\"nomes\"][i]\n",
    "    if (x1[0]!=y1[0]): print(x1[0], y1[0])\n",
    "    if (x1[1]!=y1[1]): print(x1[1], y1[1])\n",
    "    if (x2!=y2): print(x1, y2)\n",
    "#limites\n",
    "print(dados[\"total\"][\"nomes\"][i])\n",
    "print(dados[\"total\"][\"nomes\"][i+1])\n",
    "print(dados[\"total\"][\"itens\"][i])\n",
    "print(dados[\"total\"][\"itens\"][i+1])\n",
    "\n",
    "\n",
    "batch_size = 500\n",
    "min_idx = 0\n",
    "total_max = len(dados[\"total\"][\"nomes\"])\n",
    "max_idx = min(min_idx + batch_size, total_max)\n",
    "n_dims = pred.ravel().shape[0]\n",
    "px = 224\n",
    "\n",
    "# matriz de predições\n",
    "dados[\"predicoes\"] = sp.lil_matrix((len(dados[\"total\"][\"nomes\"]), n_dims))\n",
    "\n",
    "if gera_dados:\n",
    "    print(\"\\ngera predições\")\n",
    "    print(datetime.datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d %H:%M:%S'))\n",
    "    while min_idx < total_max - 1:\n",
    "\n",
    "        X = np.zeros(((max_idx - min_idx), px, px, 3))\n",
    "\n",
    "        # carrega arquivos em X\n",
    "        for i in range(min_idx, max_idx):\n",
    "            fname = dados[\"total\"][\"nomes\"][i]\n",
    "            imgcv2 = cv2.imread(fname)\n",
    "            imgcv2 = cv2.cvtColor(imgcv2, cv2.COLOR_BGR2RGB)\n",
    "            imgcv2 = cv2.resize(imgcv2, (px, px))\n",
    "            #fig=plt.figure()\n",
    "            #plt.imshow(imgcv2)\n",
    "            #img = pimage.fromarray(imgcv2)\n",
    "            img = imgcv2\n",
    "            #img = img.resize((px, px), pimage.ANTIALIAS)\n",
    "            # transforma imagem num array e carrega em X\n",
    "            img_array = kimage.img_to_array(img)\n",
    "            X[i - min_idx, :, :, :] = img_array\n",
    "\n",
    "        # pre processa X (usa função keras.applications.vgg16.preprocess_input)\n",
    "        X = preprocess_input(X)\n",
    "        these_preds = model.predict(X)\n",
    "        shp = ((max_idx - min_idx), n_dims) #shp = ((max_idx - min_idx) + 1, n_dims)\n",
    "\n",
    "        dados[\"predicoes\"][min_idx:max_idx, :] = these_preds.reshape(shp) #dados[\"predicoes\"][min_idx:max_idx + 1, :] = these_preds.reshape(shp)\n",
    "\n",
    "        min_idx = max_idx\n",
    "        max_idx = np.min((max_idx + batch_size, total_max))\n",
    "    print(\"\\ngrava dados predições\")\n",
    "    print(datetime.datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d %H:%M:%S'))\n",
    "    grava_dados_pred(dados)\n",
    "else:\n",
    "    print(\"\\nlê dados predições\")\n",
    "    print(datetime.datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d %H:%M:%S'))\n",
    "    dados = le_dados_pred() \n",
    "\n",
    "print(\"\\ndevices\")\n",
    "print(datetime.datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d %H:%M:%S'))\n",
    "print(get_available_devices())  \n",
    "\n",
    "    \n",
    "if sim_tensorflow:\n",
    "    print(\"\\ncalcula similaridades usando tensorflow\")\n",
    "    print(datetime.datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d %H:%M:%S'))\n",
    "    dados[\"sim\"] = comp_similarity_tf2(dados[\"predicoes\"])\n",
    "else:\n",
    "    print(\"\\ncalcula similaridades usando apenas numpy\")\n",
    "    print(datetime.datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d %H:%M:%S'))\n",
    "    # transforma as predicoes em uma compressed sparse row (csr)\n",
    "    dados[\"predicoescsr\"] = dados[\"predicoes\"].tocsr()\n",
    "    dados[\"sim\"] = comp_similarity(dados[\"predicoescsr\"])\n",
    "\n",
    "print(\"\\nrelatorio busca\")\n",
    "print(datetime.datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d %H:%M:%S'))\n",
    "excl = [ ]\n",
    "limiar = []\n",
    "#nivel = 0.2\n",
    "nro_arq_busca = 0\n",
    "gera_html_busca(dados, arqs, excl, N=3, minimoinicial=0.20, minimofinal=0.2)\n",
    "print(limiar)\n",
    "\n",
    "print(\"\\nrelatorio material\")\n",
    "print(datetime.datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d %H:%M:%S'))\n",
    "excl = [ ]\n",
    "limiar = []\n",
    "nro_arq_busca = 0\n",
    "gera_html_material(dados, arqs, excl, N=3, minimoinicial=0.2, minimofinal=0.2)\n",
    "print(limiar)\n",
    "print(\"Fim\")\n",
    "print(datetime.datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d %H:%M:%S'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
